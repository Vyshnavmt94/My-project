{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS tagging is the task of assigning each word in a sentence with its corresponding Part-of-Speech (POS). POS tagging is a special type of classification task called sequence labelling which means that the POS tag is assigned to the words in a sequence by considering the POS of surrounding words. Therefore, this assignment requires some contextual information about that word. This can be achieved by algorithms which can remember the context. Earlier days, Hidden Markov Model (HMM) was used for modeling such data. But, now deep learning algorithms such as RNN and LSTM can effectively model the sequential data with the help of word embedding algorithms. Word embedding algorithmslike Word2vec represent words in a vectorof given dimension. It is assumed that this vector contains the semantics (meaning) of that particular word in the given document. This word2vec works by finding the similarity between the words in the document that means, it takes the context of each word into account before generating the embedding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function to read data and to separate words and labels. Input to the function is path to the file\n",
    "\n",
    "def get_data(path):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    read_file = open(path, 'r')\n",
    "    for line in read_file:\n",
    "        line = line.replace('\\n','')\n",
    "        if line == 'newline':            #???\n",
    "            pass\n",
    "        else:\n",
    "            items = line.split('\\t')\n",
    "            texts.append(items[0])\n",
    "            labels.append(items[1])\n",
    "    read_file.close()\n",
    "\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'pos_data.txt'\n",
    "words, tags = get_data(path)\n",
    "words = [words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the word2vec model\n",
    "wvmodel = Word2Vec(words, size=100, window=1, min_count=1)  #???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(len(words[0])):\n",
    "    X.append(wvmodel.wv[words[0][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048576, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "m, n = np.shape(X)\n",
    "X = np.reshape(X, (m,n,1))\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 100, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the labels into integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(tags)\n",
    "y = label_encoder.transform(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to develop a RNN or LSTM model for POS tagging in English. You are free to use any deep learning framework and archutecture. You can also try different methods for representing data other than word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y=to_categorical(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the model into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test= train_test_split(X,y,test_size=0.30,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048576, 42)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 32)                4352      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 42)                1386      \n",
      "=================================================================\n",
      "Total params: 5,738\n",
      "Trainable params: 5,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#model.add(Embedding(100,100))\n",
    "model.add(LSTM(32,activation='relu', input_shape = x_train.shape[1:]))\n",
    "model.add(Dense(42,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 734003 samples, validate on 314573 samples\n",
      "Epoch 1/1\n",
      "734003/734003 [==============================] - 1411s 2ms/step - loss: 6.8724 - acc: 0.0312 - val_loss: 6.8896 - val_acc: 0.0313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1482fb9fef0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=32,epochs=1,verbose=1,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314573/314573 [==============================] - 105s 334us/step\n",
      "Test accuracy =  3.130275007720705\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(x_test,y_test,verbose=1)\n",
    "print(\"Test accuracy = \",score[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, 32)                1088      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,121\n",
      "Trainable params: 1,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "#model.add(Embedding(100,100))\n",
    "model1.add(SimpleRNN(32,activation='relu', input_shape = x_train.shape[1:]))\n",
    "model1.add(Dense(1,activation='sigmoid'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 734003 samples, validate on 314573 samples\n",
      "Epoch 1/2\n",
      "734003/734003 [==============================] - 636s 866us/step - loss: 6.8724 - acc: 0.0312 - val_loss: 6.8896 - val_acc: 0.0313\n",
      "Epoch 2/2\n",
      "734003/734003 [==============================] - 616s 839us/step - loss: 6.8724 - acc: 0.0312 - val_loss: 6.8896 - val_acc: 0.0313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1480176bd68>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=100,epochs=2,verbose=1,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314573/314573 [==============================] - 105s 335us/step\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(x_test,y_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
